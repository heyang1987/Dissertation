% !TeX root = proposal.tex
\chapter{Background}\label{chapter:Relatedwork}
%In this chapter, we discuss existing research related to our topic.

\section{IoT Technology}
%The term ``Internet of Things" (IoT) was first introduced by Kevin Ashton in the context of supply chain management in 1999~\cite{ashton2009internet}. Atozri et al. define IoT as a pervasive presence around us of a variety of things or objects - such as Radio-Frequency IDentification (RFID) tags, sensors, actuators, mobile phones, etc. -- which, through unique addressing scheme, are able to interact with each other and cooperate with their neighbors to reach common goals~\cite{atzori2010internet}. As various wireless sensor technologies (e.g. RFID, embedded sensors, and actuator nodes) and artificial intelligence advance rapidly during the last two decades, the definition of the IoT has evolved to more broad covering wide range of monitoring and control applications based on a network of sensing and actuating devices that controlled remotely through the Internet in many fields, such as tracking, transportation, household usage, healthcare and fitness~\cite{li2011smart, solima2016object, kelly2013towards, jia2012rfid, hassanalieragh2015health}. IoT can benefit both organizations and individual consumers in all above mentioned domains by enhancing data collection, enabling real-time response, improving access and control of internet-connected devices, increasing efficiency, productivity, and satisfaction~\cite{weinberg2015internet, porter2014smart}. With such huge social and economic potential, IoT is estimated to grow rapidly by a wide range of well-respected organizations. For example, Gartner~\cite{eddy2015gartner} has predicted over 21 billion IoT devices will be in use by 2020; IoT product and service suppliers will generate incremental revenue exceeding \$300 billion. IDC forecasts a global market for IoT will grow from \$1.9 trillion in 2013 to \$7.1 trillion in 2020. However, there exist several key security and privacy concerns associated with the rise of the IoT, including data processing and storage, privacy and security breach, etc~\cite{weinberg2015internet, lu2014overview, yu2015handling}.

Previous studies mostly focused on the technical issues of IoT technologies~\cite{fantana2013iot, lazarescu2013design, shang2012internet}. For example, Uckelmann et al. systematically explained the architecture of future IoT~\cite{uckelmann2011architectural}. Chen et al. present a vision of IoT's applications in China~\cite{chen2014vision}. Guinard et al. described the IoT’s best practices based on the web technologies and proposed several prototypes using the web principles, which connect environmental sensor nodes, energy monitoring systems, and RFID-tagged objects to the web~\cite{guinard2011internet}. However, little attention has been devoted to, from the perspective of individual consumers, understanding how will the user of IoT will trade off the above mentioned benefits and privacy concerns of IoT technology when they consider adopting it~\cite{al2016modeling, gao2014unified, mital2018adoption}.

Furthermore, researchers identified the security and privacy issues as the major challenges for consumer acceptance of the IoT technology’s user-oriented IoT applications (Medaglia \& Serbanati, 2010) [30]. Arguably, if the user find their privacy demands can not be satisfied (e.g. it's confusing to ) when using IoT devices after adopting them, they would probably finally give up using these devices.

\section{Model the Acceptance of IoT}
\subsection{Technology Acceptance Model}
The technology acceptance model (TAM) is arguably the most popular model that explains how users come to accept and use a technology~\cite{davis1989user}. TAM suggests that an individual's \textit{Behavioral Intention} to Use an information technology is significantly dependent upon the individual's perception of \textit{Perceived Usefulness} and \textit{Perceived Ease Of Use} of that information technology. Specifically, perceived usefulness is the extent to which an individual believes that using a particular information technology will have a positive impact on his/her performance. Perceived ease of use is the extent to which an individual perceives that using a particular information technology will be free of effort. TAM also proposes that perceived ease of use can explain the variance in perceived usefulness.
TAM have applied to a wide range of technology adoption contexts~\cite{wixom2005theoretical}, such as the adoption of PC~\cite{venkatesh2001longitudinal}, smartphones~\cite{park2007acceptance}, mobile marketing~\cite{bauer2005driving}, Internet banking~\cite{pikkarainen2004consumer}, facebook~\cite{lee2012effect, rauniar2014technology}, and online shopping~\cite{gefen2003trust}.

\subsection{UTAUT}
The unified theory of acceptance and use of technology (UTAUT) is a technology acceptance model proposed by Venkatesh et al.~\cite{venkatesh2003user}. Compared to TAM, UTAUT model identifies four key factors: 1) performance expectancy, 2) effort expectancy, 3) social influence, and 4) facilitating conditions related to predicting behavioral intention to use a technology and actual technology use primarily in organizational contexts. The first three factors are theorized and found to influence behavioral intention to use a technology, while behavioral intention and facilitating conditions determine technology use. UTAUT also identifies four moderators (i.e., age, gender, experience, and voluntariness).

These relationships are also confirmed by Weerakkody, ElHaddadeh, Al-Sobhi, Shareef, and Dwivedi (2013) [39] in the context of electronic government, or electronic learning
(Wang et al., 2009) [45], cloud computing (Lian, 2015) [43], and electronic commerce. Figure 2 shows the conceptual model of UTAUT. The key variables of UTAUT is developed based on the
similarities with other variables from other theories and
models. For example, performance expectancy is considered
similar to perceived usefulness in TAM. Table 1 shows the
core variables of UTAUT. Venkatesh et al. (2003) [38] combined the previous models of
technology adoption to come up with UTAUT which is
design specifically to investigate users’ acceptance of a new
technology and it has explanatory power higher than
previous models such as TAM. Thus, the UTAUT model is
suitable for understanding the acceptance of IoT services. 

\subsection{The Acceptance of IoT}
Researchers have attempted to identify the factors that affect
the acceptance of IoT by customers. For example, Gao and
Bai (2014) [16] investigated the factors that affect the
acceptance of IoT in China. Mainly, their study used the
factors of TAM such as perceived ease of use and perceived
usefulness along with other factors such as trust, social
influence, perceived enjoyment, and perceived behavioral
control. A total of 368 respondents have participated in the
study. The results indicate that perceived usefulness,
perceived ease of use, social influence, perceived enjoyment
and perceived behavioral control have significant effect on
behavioral intention to use the IoT. Acquity Group, (2014)
[1] investigated the concerns of customers to adopt the IoT.
A total of 2000 customers in US have been surveyed. The
findings showed that awareness of the technology,
usefulness, price (cost), security, privacy are the main
concerns of the customers. 

%\subsection{ (original work)}
%All the studies have focused on adding a few new variables based on contexts. The problem is also that we have so many new variables in different contexts added to the original theory that the theory is no longer parsimonious, which is also a challenge for theory development. While
%Gefen et al. (2003) added trust, Pedersen (2005), analyzed based on 
%cognitive and social factors, Porter and Donthu (2006) incorporated demographic variables, Yu et al. (2005) introduced perceived enjoyment and trust.
%
%
%We conducted a preliminary/pilot study on Clemson University Campus with an aim to investigate the various aspects involved in accepting technologies by the potential IoT users and validate the TAM Model in IoT domain.
% 
%From our study, the factors that affect the acceptance of IoT devices can be summarized into following three aspects: Privacy, Usability, and Affordability. As shown in Figure~\ref{fig:AcceptingProcess}, while making the decision on whether to adopt the IoT technology, the users do a three-way calculus based on the trade-off between privacy, usability and affordability. Users are more likely to adopt an IoT device with high usability, privacy, and affordability. Within the above three aspects, only the usability and privacy  are relevant to our research questions. Although we can not do anything to affordability aspect in our study, the results still provide a good insight for manufacturers about the trade-off between usability, privacy, and affordability. Next, we present our analysis to the effect of usability and privacy to the acceptability of IoT systems/devices.

%\section{Personalization in IoT Systems}
\section{Privacy in IoT}
One of the key features of IoT environments is that they have a high potential for providing personalized services to their users~\cite{vallee2016personalization, etzion2014personalization, hemant2015internet}. For example, Russell et al.~\cite{russell2015personalization} use unobtrusive sensors and micro-controller to realize a human detection for further providing personalization in a scenario of a family making use of the IoT in their daily living. Henka et al.~\cite{henka2016personalizing} propose an approach to personalize services in (household) IoT using the Global Public Inclusive Infrastructure's~\cite{vanderheiden2011creating} preference set to describe an individual's needs and preferences, and then adapting a smart environment accordingly.

Researchers have shown that privacy plays a limiting role in users' adoption of personalized services~\cite{teltzrow_2004}.  For example, Awad and Krishnan~\cite{awad_2006} show that privacy concerns inhibit users' use of personalized services, and Sutanto et al.~\cite{sutanto_2013} demonstrated that privacy concerns can prevent people from using a potentially beneficial personalized application. Kobsa et al.~\cite{kobsa_2016} demonstrate that the personalization provider is an important determinant of users' privacy concerns.

Moreover, research has shown  users' willingness to provide personal information to personalized services depends on both the risks and benefits of disclosure~\cite{phelps_2000,ho_2006,hui_2006}, and researchers therefore claim that both the benefits and the risks meet a certain threshold~\cite{treiblmaier_2007}, or that they should be in balance~\cite{chellappa_2005}.

The argument that using user-generated data for personalization can result in privacy concerns has also been made in IoT environments~\cite{worthy_trust_2016}. One of the first examples in this regard was the work by Sheng et al.~\cite{sheng_experimental_2008}, who showed that users of ``u-commerce'' services (IoT-driven mobile shopping) felt less inclined to use personalized (rather than non-personalized) u-commerce services, unless the benefits were overwhelming (i.e., providing help in an emergency).

In response, researchers have proposed frameworks with guidelines for evaluating the security and privacy of consumer IoT applications, devices, and platforms~\cite{perera_privacy-by-design_2016, loi_systematically_2017}. Most of these guidelines are focused on minimizing data acquisition, storage, and collection sources. Along these guidelines, several researchers have proposed architectures that restrict unwanted access to users' data by IoT devices. For example, Davies et al. propose ``privacy mediators'' to the data distribution pipeline that would be responsible for data redaction and enforcement of privacy policies even before the data is released from the user's direct control~\cite{davies_privacy_2016}. Likewise, Jayraman et al.'s privacy preserving architecture aggregates requested data to preserve user privacy~\cite{jayaraman_privacy_2017}.

Other research has considered IoT privacy from the end-user perspective~\cite{feth_user-centered_2017}, both when it comes to research (e.g., Ur et al. investigated how privacy perceptions differ among teens and their parents in smart security systems installed in homes~\cite{ur_intruders_2014}) and design (e.g., Williams et al. highlight the importance of designing interfaces to manage privacy such that they are usable to the end users of IoT devices~\cite{williams2016perfect}, and Feth et al. investigated the creation of understandable and usable controls~\cite{feth_user-centered_2017}). The current paper follows this approach, by outlining a novel methodology for the development of usable and efficient privacy-setting interfaces and applying it to household IoT privacy management. 

\section{Existing Privacy Control Schemes}
Previous studies in mobile privacy (e.g.,\cite{felt2012android}) have proven that mobile interfaces lack the potential to provide the necessary user privacy information and control for both Android and iOS systems~\cite{lin2014modeling}. Several solutions from literature have been proposed from then on to improve mobile privacy protection and offer users more privacy control (e.g.,~\cite{beresford2011mockdroid}). These leads into rapid improvement of privacy management of current mobile systems (i.e., from Android 6.0+ and iOS 5.0+), providing more control on the user's privacy settings.

Android permission systems can be mainly categorized as Ask On Install (AOI) and Ask On First Use (AOFU) privacy models~\cite{tsai2017turtle, wijesekera2017feasibility}. In AOI\footnote{\url{https://support.google.com/googleplay/answer/6014972?co=GENIE.Platform\%3DAndroid&hl=en}} (Android 5.9 and below), the permissions are asked in bulk before installing a TP app. The user's option is only to allow or deny all, which clearly gives less privacy control. Also, only a few number of users read and pay attention to the install time permissions, and even fewer than this can understand their meaning~\cite{felt2012android,kelley2012conundrum}. These issues made room for TP apps that manage app privacy such as Turtleguard~\cite{tsai2017turtle} and Mockdroid~\cite{beresford2011mockdroid}. %, Advanced Permission Manager\cite{},Xprivacy\cite{}, Permission Master~\cite{}, DonkeyGuard\cite{}, AppOps\cite{}. These apps help user to manage their privacy settings. 

On the other hand, the AOFU model~\cite{tsai2017turtle} (Android 6.0 and above) only asks permissions during the first use of an app and when an app uses a specific feature that needs the respective permission. In this case, the user grants the permission during the actual provision of the service and will be able to weigh his willingness to share vs the utility of the app. The user can also revisit and review permissions in their phone privacy settings for each app. This model makes user more informed and gives them more control as the previous model does not allow users to be informed effectively\cite{fu2014field}. Moreover, it has been proven that interactive notification is more efficient in informing users request access\cite{fu2014field}. It is noteworthy to discuss this two models as currently, 34\% of the Android users are still using the AOI model\footnote{\url{https://developer.android.com/about/dashboards/index.html}}.

A few privacy management were developed to ease the task of controlling personal data for smartphone users. For instance, ipShield\cite{chakraborty2014ipshield} is a context-aware privacy framework for mobile systems that provides users with great control of their data and inference risks. My Data Store \cite{ref:vescovi} offers a set of tools to manage, control and exploit personal data by enhancing an individual’s awareness on the value of their data. Similarly, Databox \cite{ref:chaudhry} enables individuals to coordinate the collection of their personal data, and make those data available for specific purposes. However, these data managers do not include user privacy profiling and recommendation in the complex IoT environment. Privacy can also be protected by providing different anonymity levels of data that are given to the third parties. However, it might not be possible to implement the most effective privacy standards such as data obfuscation due to numerous trade-offs and restrictions, especially in the healthcare and fitness domain.

In smartphone domain, privacy nudging is an effective scheme to increase users' awareness~\cite{almuhimedi2015your}. Privacy nudging allows users to be informed and aware on both their privacy settings and how the third party applications access their data~\cite{liu2016follow,fu2014field}. It has been showed that 78.7\%~\cite{liu2016follow} of the privacy recommendation were adopted by the smartphone users. However, such nudging are problematic for IoT, because IoT devices are supposed to operate in the background. Moreover, as the penetration of IoT devices in our homes continues to increase, nudging would become a constant noise which users will soon start to ignore, like software EULAs~\cite{good2005spyware} or privacy policies~\cite{jensen2004privacy}. At the same time,
Privacy nudges lack the personalization and provide general recommendation.  


Another approach that is more user-centric is the user-tailored privacy~\cite{knijnenburg2017privacy}. It models users’ privacy concerns and provides them with adaptive privacy decision support. This model can be seen as personalized ``smart nudges'' where the recommendation is aligned with the user's privacy preference. User-tailored privacy aids users in making privacy decisions by providing them the right amount of both the privacy-related information associated to them and the useful privacy control that do not overwhelm or mislead them. However, in practice it is hard to implement general privacy model as the idea is too broad and abstract especially in the diversity of privacy perception of users. 

%\textit{khealth} is an IoT framework based on a personalized digital health care information system that protects users from third parties' advertisements~\cite{sharma2018toward}. Pejovic and Musolesi~\cite{Pejovic2014} presented the design and implementation of an efficient online learner that can serve as a basis for recognizing opportune moments for interruption. The design of the library is based on an in-depth study of human interruptibility. Comparatively, our work tries to find the most suitable privacy-setting profile for each user based on their privacy preference on different household IoT scenarios.

\section{Privacy-Setting Interfaces}
Beyond prompts, one can regulate privacy with global settings. The most basic privacy-setting interface is the traditional ``access control matrix'', which allows users to indicate which entity gets to access what type of information~\cite{sandhu1994access}. This approach can be further simplified by grouping recipients into relevant semantic categories, such as Google+'s \emph{circles}~\cite{watson12}. Taking a step further, Raber et al.~\cite{197908} proposed \emph{Privacy Wedges} to manipulate privacy settings. Privacy Wedges allow users to make privacy decisions using a combination of semantic categorization (the various wedges) and inter-personal distance (the position of a person on the wedge). Users can decide who gets to see various posts or personal information by ``coloring'' parts of each wedge. 

Privacy wedges have been tested on limited numbers of friends, and in the case of household IoT they are likely to be insufficient, due to the complexity of the decision space. To wit, IoT privacy decisions involve a large selection of devices, each with various sensors that collect data for a range of different purposes. This makes it complicated to design an interface that covers every possible setting~\cite{williams2016perfect}. A wedge-based interface will arguably not be able to succinctly represent such complexity, and therefore either be impossible, or still lead to a significant amount of information and choice overload. 

We propose a data-driven approach to solve this problem: statistical analysis informs the construction of a layered settings interface, while machine learning-based privacy prediction helps us find smart privacy profiles.

\section{Privacy Prediction}
Several researchers have proposed privacy prediction as a solution to the privacy settings complexity problem---an approach known as ``user-tailored privacy'' (UTP)~\cite{knijnenburg2017}. Systems that implement UTP first predict users' privacy preferences and behaviors based on their known characteristics. They then use these predictions to provide automatic default settings or suggestions in line with users' disclosure profiles, to educate users' about privacy features they are unaware of, to tailor the privacy-setting user interfaces to make it easier for users to engage with their preferred privacy management tools, or to selectively restrict the types of personalization a system is allowed engage in.

Most existing work in line with this approach has focused on providing automatic default settings. For example, Sadeh et al.~\cite{sadeh2009understanding} used a k-nearest neighbor algorithm and a random forest algorithm to predict users' privacy preferences in a location-sharing system, based on the type of recipient and the time and location of the request. They demonstrated that users had difficulties setting their privacy preferences, and that the applied machine learning techniques can help users to choose more accurate disclosure preferences. Similarly, Pallapa et al.~\cite{pallapa2014adaptive} present a system which can determine the required privacy level in new situations based on the history of interaction between users. Their system can efficiently deal with the rise of privacy concerns and help users in a pervasive system full of dynamic interactions.

Dong et al.~\cite{dong2016ppm} use a binary classification algorithms to give users personalized advice regarding their privacy decision-making practices on online social networks. They found that J48 decision trees provided the best results. Li and et al.~\cite{li2017cross} similarly use J48 to demonstrate that taking the user's cultural background into account when making privacy predictions improves the prediction accuracy. Our data stems from a culturally homogeneous population (U.S. Mechanical Turk workers), so cultural variables are outside the scope of our study. We do however follow these previous works in using J48 decision trees in our prediction approach.

We further extend this approach using \emph{clustering} to find several smart default policies (``profiles''). This is in line with Fang et al.~\cite{fang2010privacy}, who present an active learning algorithm that comes up with privacy profiles for users in real time. Since our approach is based on an existing dataset, our algorithm does not classify users in real time, but instead creates a static set of profiles `offline', from which users can subsequently choose. This avoids cold start problems, and does not rely on the availability of continuous real-time behaviors. This is beneficial for household IoT privacy settings, because users often specify their settings in these systems in a ``single shot'', leaving the settings interface alone afterwards.

Ravichandran et al.~\cite{ravichandran2009capturing} employ an approach similar to ours, using $k$-means clustering on users' contextualized location sharing decisions to come up with several default policies. They showed that a small number of policies could accurately reflect a large part of the location sharing preferences. We extend their approach to find the best profiles based on various novel clustering approaches, and take the additional step of designing user interfaces that incorporate the best solutions.

%\section{Data-driven design}
%In our previous work~\cite{bahiratiui2018}, we leveraged data collected by Lee and Kobsa~\cite{lee2016understanding}, which asked 200 participants about their intention to allow or reject the IoT features presented in 14 randomized scenarios. They varied the scenarios in a mixed fractional factorial design along the following dimensions: `Who', `What', `Where', `Reason', `Persistence'.
%
%We conducted a statistical analysis on this dataset to determine the relative influence of these parameters on users' privacy-related decisions. The outcome informed the design of a `layered interface', which presents privacy settings with the most prominent influence first, relegating less prominent aspects to subsequently lower layers. Users can use this interface for making manual privacy settings.
%
%We also conducted a machine learning analysis to predict participants' reactions to the scenarios. We used the outcomes of this analysis to develop a ``smart'' default setting, which preempts the need for many users to manually change their settings~\cite{smith2013choice}. However, since people differ extensively in their privacy preferences~\cite{olson2005study}, it is not possible to achieve an optimal default that is the same for everyone. Instead, different people may require vastly different settings~\cite{knijnenburg2013dimensionality, olson2005study, wisniewski2017making}. By partitioning the participants in a number of clusters, we were able to construct a number of `privacy profiles', which represented a selection of default settings for the user to choose from. These profiles automate (part of) the privacy-setting task.
%
%As noted in the introduction, our current paper builds upon this existing work by applying it to a newly collected dataset focused on household IoT privacy decisions, and by refining both the statistical and machine learning procedures underlying this approach. The resulting procedure can be considered a blueprint for researchers interested in applying data-driven design to their (privacy-)settings interfaces.


